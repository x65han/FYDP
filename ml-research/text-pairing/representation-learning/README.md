# Mudio Text Pairing Pipeline -- Representation Learning

### Motivation
The overall objective of Mudio is to extract the semantics and emotions from short videos and pass them to the user in the form of music and melody.
With Mudio, the visually impaired will be able to admire the scenery in front of them instead of simply detecting where the objects are.
Mudio provides a chance for the visually impaired to perceive the world comprehensively, which might potentially reduce the likelihood of mental illness due to the loss of sight.

This Text Pairing pipeline is the second Deep Learning component of this project, which aims to match generated caption with appropriate lyrics/song.
Representation Learning approach involves the use of auto-encoders to reconstruct both sides and then set up a binary classification model (probably large margin) to match the embeddings.

### Our R&D Interface
TODO

### Research & Development contributors:
Yuanxin(Michael) Wang

Undergraduate Research Assistant @ [UWaterloo NLP Lab](https://ov-research.uwaterloo.ca/NLP_lab.html)

[Follow on Github](https://github.com/MichaelYxWang)

[Connect on Linkedin](https://www.linkedin.com/in/michael-yuanxin-wang/)


### References
TODO
