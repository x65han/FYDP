{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5. Text Mataching with Infersent.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcFRXPfnNqbW",
        "colab_type": "text"
      },
      "source": [
        "## Setup\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmVPNKnnSjL8",
        "colab_type": "code",
        "outputId": "d9e6b460-aefe-4579-a3c0-4e78ac99f845",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import time\n",
        "import shutil\n",
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "import google.colab as colab\n",
        "import zipfile\n",
        "import random\n",
        "import json\n",
        "from collections import defaultdict\n",
        "import cv2\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from pprint import pprint\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZ3xk-0Dczdg",
        "colab_type": "text"
      },
      "source": [
        "### Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxIyTxXml65l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mount_google_drive():\n",
        "\t'''\n",
        "\t# Functionality\n",
        "\t\tMount google drive. Since colab does not save files, we want to make it easier to directly access files in google drive.\n",
        "\t# Arguments\n",
        "\t\tNothing\n",
        "\t# Returns\n",
        "\t\tdrive_root: the working directory mounted\n",
        "\t'''\n",
        "\tmount_directory = \"/content/gdrive\"\n",
        "\tdrive = colab.drive\n",
        "\tdrive.mount(mount_directory, force_remount=True)\n",
        "\tdrive_root = mount_directory + \"/\" + list(filter(lambda x: x[0] != '.', os.listdir(mount_directory)))[0]\n",
        "\treturn drive_root"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4LE1Ewyc4tD",
        "colab_type": "code",
        "outputId": "87b1b969-968b-4d22-dec4-cec76096535b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "ROOT_DIR =  mount_google_drive()\n",
        "CHECKPOINT_ROOT = ROOT_DIR+ \"/FYDP/captioning/checkpoints/\"\n",
        "DATASET_DIR = ROOT_DIR + \"/FYDP/Dataset/\"\n",
        "\n",
        "\n",
        "def get_checkpoint_path(epoch=None):\n",
        "    if epoch is None:\n",
        "        return os.path.abspath(CHECKPOINT_ROOT + \"weights\")\n",
        "    else:\n",
        "        return os.path.abspath(CHECKPOINT_ROOT + \"weights_{}\".format(epoch))\n",
        "      \n",
        "# example of checkpoint dir\n",
        "print(get_checkpoint_path(4))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/FYDP/captioning/checkpoints/weights_4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFYUA4D7bEIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc-KgDpCWAYc",
        "colab_type": "code",
        "outputId": "3226ccbb-72b5-4bd1-eb48-c134ed518f8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "shutil.copytree(ROOT_DIR + \"/FYDP/utils/\", \"utils/\")\n",
        "shutil.copy(ROOT_DIR + \"/FYDP/models.py\", \"models.py\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'models.py'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eve39P76V_4Y",
        "colab_type": "code",
        "outputId": "e58b7a10-ede6-4ab5-d953-e1e762c42009",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "from utils.file_utils import *\n",
        "from utils.image_utils import *\n",
        "from utils.generator_utils import *\n",
        "from utils.tqdm_utils import *\n",
        "from utils.keras_utils import *"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXwKMLroYgFS",
        "colab_type": "text"
      },
      "source": [
        "## Infersent Init\n",
        "Never run this section unless **First Run**. This will take tons of time and disk space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-q98cTgYfNz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://github.com/facebookresearch/InferSent"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha_zoB7oYkoa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !mkdir GloVe\n",
        "# !curl -Lo GloVe/glove.840B.300d.zip http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
        "# !unzip GloVe/glove.840B.300d.zip -d GloVe/\n",
        "# !mkdir fastText\n",
        "# !curl -Lo fastText/crawl-300d-2M.vec.zip https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip\n",
        "# !unzip fastText/crawl-300d-2M.vec.zip -d fastText/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6T6RkwJYrQf",
        "colab_type": "code",
        "outputId": "a49398cf-8966-4ef1-b080-1c2efaebf2ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# !mkdir encoder\n",
        "# !curl -Lo encoder/infersent1.pkl https://dl.fbaipublicfiles.com/infersent/infersent1.pkl\n",
        "# !curl -Lo encoder/infersent2.pkl https://dl.fbaipublicfiles.com/infersent/infersent2.pkl"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  146M  100  146M    0     0  10.3M      0  0:00:14  0:00:14 --:--:-- 12.1M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  146M  100  146M    0     0  10.4M      0  0:00:14  0:00:14 --:--:-- 11.9M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YLaY5f9hNI-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# shutil.copytree(\"GloVe/\", ROOT_DIR + \"/FYDP/nli_utils/GloVe/\")\n",
        "# shutil.copytree(\"fastText/\", ROOT_DIR + \"/FYDP/nli_utils/fastText/\")\n",
        "# shutil.copytree(\"encoder/\", ROOT_DIR + \"/FYDP/nli_utils/encoder/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0h4eW6MRmcNL",
        "colab_type": "text"
      },
      "source": [
        "## Infersent Fitting\n",
        "\n",
        "Store trained Infersent model and numpy embeddings.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_elMp5Zd-02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from models import InferSent\n",
        "\n",
        "def build_nli_net():\n",
        "  V = 2\n",
        "  MODEL_PATH = ROOT_DIR + '/FYDP/nli_utils/encoder/infersent%s.pkl' % V\n",
        "  params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
        "                  'pool_type': 'max', 'dpout_model': 0.0, 'version': V}\n",
        "  infersent = InferSent(params_model)\n",
        "  infersent.load_state_dict(torch.load(MODEL_PATH))\n",
        "  return infersent"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctQzuikUmfps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1) Load our pre-trained model (in encoder/):\n",
        "infersent = build_nli_net()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnCh-m9Homiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2) Set word vector path for the model:\n",
        "W2V_PATH = ROOT_DIR + '/FYDP/nli_utils/fastText/crawl-300d-2M.vec'\n",
        "infersent.set_w2v_path(W2V_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6GwlFXbo9mE",
        "colab_type": "code",
        "outputId": "7e8a9b76-d2bf-4678-b6b4-7ab8ace12f70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# NOT necessary\n",
        "# 3) Build the vocabulary of word vectors (i.e keep only those needed):\n",
        "# infersent.build_vocab(sentences, tokenize=True)\n",
        "infersent.build_vocab_k_words(K=100000)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size : 100000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6Ami3YPsVUD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 4) Encode your sentences (list of n sentences):\n",
        "for file_name in get_all_files_from_dir(DATASET_DIR + \"songs/\"):\n",
        "  with open(file_name, 'r') as f:\n",
        "    sentences = f.readlines()\n",
        "  embeddings = infersent.encode(sentences, tokenize=True)\n",
        "  np.save(DATASET_DIR + \"song_embeds/\" + file_name.split(\"/\")[-1].split(\".\")[0] + \".npy\", embeddings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsO3Z7bedHE4",
        "colab_type": "text"
      },
      "source": [
        "## Test\n",
        "\n",
        "Load pretrained model and embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoO5Kl-_EPgn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cosine(u, v):\n",
        "  # compute the similarity between two embeddings\n",
        "  # u and v are matrices!\n",
        "    return np.einsum('ij,ij->i', u, v) / ((np.linalg.norm(u, axis=1) * np.linalg.norm(v, axis=1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MS9_9zq8dRt5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "101568ac-f203-4d24-8c7e-de654db32d06"
      },
      "source": [
        "cosine(infersent.encode(['the cat eats.']), infersent.encode(['the cat is hungry.']))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.75352097], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfQBA1PdjspR",
        "colab_type": "text"
      },
      "source": [
        "## Song Ranking Experiment\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1jqGPovlew9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_score(caption, song_emb_files):\n",
        "  best_song_index = 0\n",
        "  best_score = 0\n",
        "  caption_emb = infersent.encode([caption])\n",
        "  for index, file_name in enumerate(song_emb_files):\n",
        "    song_emb = np.load(file_name)\n",
        "    score = np.max(cosine(np.repeat(caption_emb, song_emb.shape[0], axis=0), song_emb))\n",
        "    if score > best_score:\n",
        "      best_score = score\n",
        "      best_song_index = index\n",
        "  return best_song_index, best_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Men1KZTrKLLc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "633f09be-e079-4325-d5a0-664819b7ef8b"
      },
      "source": [
        "tic = time.time()\n",
        "caption = \"It is snowy outside\"\n",
        "best_song_index, best_score = compute_score(caption, get_all_files_from_dir(DATASET_DIR + \"song_embeds/\"))\n",
        "toc = time.time()\n",
        "print(\"It takes\", str(toc - tic), \"seconds to forward pass\", len(get_all_files_from_dir(DATASET_DIR + \"song_embeds/\")), \"songs.\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "It takes 0.1624903678894043 seconds to forward pass 26 songs.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt3rTO7mLWgv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "7da52072-14ad-4519-9973-f936eb554561"
      },
      "source": [
        "with open(get_all_files_from_dir(DATASET_DIR + \"songs/\")[best_song_index], \"r\") as f:\n",
        "  pprint(f.readlines())"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Oh, the weather outside is frightful\\n',\n",
            " 'But the fire is so delightful\\n',\n",
            " \"And since we've no place to go\\n\",\n",
            " 'Let it snow, let it snow, let it snow\\n',\n",
            " \"Man it doesn't show signs of stoppin'\\n\",\n",
            " \"And I brought me some corn for poppin'\\n\",\n",
            " 'The lights are turned way down low\\n',\n",
            " 'Let it snow, let it snow, let it snow\\n',\n",
            " 'When we finally kiss good-night\\n',\n",
            " \"How I'll hate going out in the storm\\n\",\n",
            " 'But if you really hold me tight\\n',\n",
            " \"All the way home I'll be warm\\n\",\n",
            " 'And the fire is slowly dying\\n',\n",
            " \"And, my dear, we're still good-bye-ing\\n\",\n",
            " 'But as long as you love me so\\n',\n",
            " 'Let it snow, let it snow, and snow\\n',\n",
            " 'When we finally kiss good-night\\n',\n",
            " \"How I'll hate going out in the storm\\n\",\n",
            " 'But if you really grab me tight\\n',\n",
            " \"All the way home I'll be warm\\n\",\n",
            " 'Oh the fire is slowly dying\\n',\n",
            " \"And, my dear, we're still good-bye-ing\\n\",\n",
            " 'But as long as you love me so\\n',\n",
            " 'Let it snow, let it snow, let it snow']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIL-8gskUXT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}